{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c714614",
   "metadata": {},
   "source": [
    "## A minimalist example for recovering sparse graphs using `uGLAD`\n",
    "\n",
    "Fitting uGLAD on a erdos-renyi random sparse graph with samples obtained from a corresponding multivariate Gaussian distribution.    \n",
    "\n",
    "### About `uGLAD` \n",
    "Sparse graph recovery by optimizing deep unrolled networks. This work proposes `uGLAD` which is a unsupervised version of a previous `GLAD` model (GLAD: Learning Sparse Graph Recovery (ICLR 2020 - [link](<https://openreview.net/forum?id=BkxpMTEtPB>)).  \n",
    "\n",
    "Key benefits & features:  \n",
    "- Solution to Graphical Lasso: A better alternative to solve the Graphical Lasso problem as\n",
    "    - The neural networks of the uGLAD enable adaptive choices of the hyperparameters which leads to better performance than the existing algorithms  \n",
    "     - No need to pre-specify the sparsity related regularization hyperparameters    \n",
    "    - Requires less number of iterations to converge due to neural network based acceleration of the unrolled optimization algorithm (Alternating Minimization)    \n",
    "    - GPU based acceleration can be leveraged  \n",
    "    - Novel `consensus` strategy which robustly handles missing values by leveraging the multi-task learning ability of the model   \n",
    "    - Multi-task learning mode that solves the graphical lasso objective to recover multiple graphs with a single `uGLAD` model  \n",
    "- Glasso loss function: The loss is the logdet objective of the graphical lasso `1/M(-1*log|theta|+ <S, theta>)`, where `M=num_samples, S=input covariance matrix, theta=predicted precision matrix`.  \n",
    "- Ease of usability: Matches the I/O signature of `sklearn GraphicalLassoCV`, so easy to plug-in to the existing code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193b57a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harshx/anaconda3/envs/uGLAD\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "# reloads modules automatically before entering the \n",
    "# execution of code typed at the IPython prompt.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# install jupyter-notebook in the env if the prefix does not \n",
    "# show the desired virtual env. \n",
    "print(sys.prefix)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db9f5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d45c7",
   "metadata": {},
   "source": [
    "# 1. Synthetic data convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f589ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_theta: (1, 10, 10), Samples (1, 500, 10)\n"
     ]
    }
   ],
   "source": [
    "from uGLAD.utils.prepare_data import get_data\n",
    "from uGLAD.utils.metrics import reportMetrics\n",
    "\n",
    "# Xb = samples batch, trueTheta = corresponding true precision matrices\n",
    "Xb, true_theta = get_data(\n",
    "    num_nodes=10, \n",
    "    sparsity=[0.2, 0.2], \n",
    "    num_samples=500, \n",
    "    batch_size=1,\n",
    "    eig_offset=1, \n",
    "    w_min=0.5,\n",
    "    w_max=1\n",
    ")\n",
    "print(f'true_theta: {true_theta.shape}, Samples {Xb.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6936ae",
   "metadata": {},
   "source": [
    "### The uGLAD model\n",
    "\n",
    "Learning details:  \n",
    "1. Initialize learnable `GLAD` parameters  \n",
    "2. Run the GLAD model  \n",
    "3. Get the glasso-loss  \n",
    "4. Backprop  \n",
    "\n",
    "Possible solutions if `uGLAD` does not converge:  \n",
    "1. Increase number of training EPOCHS\n",
    "2. Lower the learning rate    \n",
    "3. Please re-run. This will run the optimization with different initializations  \n",
    "4. Change the INIT_DIAG=0/1 in the `GLAD` model parameters  \n",
    "5. Increase `L`, the number of unrolled iterations of `GLAD`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1da718",
   "metadata": {},
   "source": [
    "### Running the uGLAD-Direct mode\n",
    "\n",
    "- Directly optimize the uGLAD model on the complete data X\n",
    "- Optimizes the model to minimize the glasso-loss on X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44fa2c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running uGLAD\n",
      "Direct Mode\n",
      "Total runtime: 18.008416175842285 secs\n",
      "\n",
      "uGLAD: {'FDR': 0.2777777777777778, 'TPR': 1.0, 'FPR': 0.15625, 'SHD': 5, 'nnzTrue': 13, 'nnzPred': 18, 'precision': 0.7222222222222222, 'recall': 1.0, 'Fbeta': 0.8387096774193549, 'aupr': 0.9999999999999998, 'auc': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from uGLAD import main as uG\n",
    "\n",
    "# Initialize the model\n",
    "model_uGLAD = uG.uGLAD_GL()  \n",
    "\n",
    "# Fit to the data\n",
    "model_uGLAD.fit(\n",
    "    Xb[0],\n",
    "    centered=False,\n",
    "    epochs=300,\n",
    "    lr=0.002,\n",
    "    INIT_DIAG=0,\n",
    "    L=15,\n",
    "    verbose=False, \n",
    "    k_fold=0,  # Direct mode\n",
    "    mode='direct'\n",
    ")  \n",
    "\n",
    "# Comparing with true precision matrix\n",
    "compare_theta_uGLAD = reportMetrics(\n",
    "        true_theta[0], \n",
    "        model_uGLAD.precision_\n",
    "    )\n",
    "print(f'uGLAD: {compare_theta_uGLAD}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c27c15",
   "metadata": {},
   "source": [
    "### Running the uGLAD-CV mode \n",
    "\n",
    "- Finds the best model by doing cross-fold validation on the input samples X\n",
    "- Chooses the model which performs best in terms of glasso-loss on held-out data\n",
    "- More conservative than the direct mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9d3ca4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running uGLAD\n",
      "CV mode: 3-fold\n",
      "Total runtime: 58.79391002655029 secs\n",
      "\n",
      "uGLAD: {'FDR': 0.4090909090909091, 'TPR': 1.0, 'FPR': 0.28125, 'SHD': 9, 'nnzTrue': 13, 'nnzPred': 22, 'precision': 0.5909090909090909, 'recall': 1.0, 'Fbeta': 0.7428571428571429, 'aupr': 0.9999999999999998, 'auc': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from uGLAD import main as uG\n",
    "\n",
    "# Initialize the model\n",
    "model_uGLAD = uG.uGLAD_GL()  \n",
    "\n",
    "# Fit to the data\n",
    "model_uGLAD.fit(\n",
    "    Xb[0],\n",
    "    centered=False,\n",
    "    epochs=400,\n",
    "    lr=0.002,\n",
    "    INIT_DIAG=0,\n",
    "    L=15,\n",
    "    verbose=False,\n",
    "    k_fold=3, \n",
    "    mode='cv'\n",
    ")  \n",
    "\n",
    "# Comparing with true precision matrix\n",
    "compare_theta_uGLAD = reportMetrics(\n",
    "        true_theta[0], \n",
    "        model_uGLAD.precision_\n",
    "    )\n",
    "print(f'uGLAD: {compare_theta_uGLAD}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d862d3",
   "metadata": {},
   "source": [
    "### Comparison with sklearn's GraphicalLassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528b2d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCD: {'FDR': 0.5357142857142857, 'TPR': 1.0, 'FPR': 0.46875, 'SHD': 15, 'nnzTrue': 13, 'nnzPred': 28, 'precision': 0.4642857142857143, 'recall': 1.0, 'Fbeta': 0.6341463414634146, 'aupr': 0.9999999999999998, 'auc': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import GraphicalLassoCV\n",
    "\n",
    "model_BCD = GraphicalLassoCV().fit(Xb[0])\n",
    "# Compare with theta\n",
    "compare_theta_BCD = reportMetrics(\n",
    "    true_theta[0], \n",
    "    model_BCD.precision_\n",
    ")\n",
    "print(f'BCD: {compare_theta_BCD}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3050887a",
   "metadata": {},
   "source": [
    "# 2. Handling missing values\n",
    "Running `uGLAD` model in mode=`missing`:\n",
    "- Leverages the multi-task learning feature of the `uGLAD` model\n",
    "- Uses the novel `consensus` strategy to robustly handle the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a36f4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dropout noise to Xb\n",
    "from uGLAD.utils.prepare_data import add_noise_dropout\n",
    "from uGLAD.main import mean_imputation\n",
    "import numpy as np\n",
    "\n",
    "# Adding np.NaNs to introduce missing values\n",
    "Xb_miss = add_noise_dropout(Xb, dropout=0.80)\n",
    "# Doing mean imputation for basic statistical comparsion\n",
    "B, M, D = Xb_miss.shape\n",
    "Xb_mean = [] \n",
    "for b in range(B):\n",
    "    X_miss = Xb_miss[b].copy()\n",
    "    X_miss = X_miss.reshape(1, M, D)\n",
    "    Xb_mean.append(mean_imputation(X_miss).reshape(M, D))\n",
    "Xb_mean = np.array(Xb_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec82a1e",
   "metadata": {},
   "source": [
    "### Running the `uGLAD-miss` model in missing data mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34acefd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running uGLAD\n",
      "Handling missing data\n",
      "Creating K=5 row-subsampled batches\n",
      "Getting the final precision matrix using the consensus strategy\n",
      "Total runtime: 68.35704565048218 secs\n",
      "\n",
      "uGLAD: {'FDR': 0.0, 'TPR': 0.07692307692307693, 'FPR': 0.0, 'SHD': 12, 'nnzTrue': 13, 'nnzPred': 1, 'precision': 1.0, 'recall': 0.07692307692307693, 'Fbeta': 0.14285714285714285, 'aupr': 0.3435897435897436, 'auc': 0.5384615384615384}\n"
     ]
    }
   ],
   "source": [
    "from uGLAD import main as uG\n",
    "\n",
    "# Initialize the model\n",
    "model_uGLAD = uG.uGLAD_GL()  \n",
    "\n",
    "# Fit to the data\n",
    "model_uGLAD.fit(\n",
    "    Xb_miss[0],\n",
    "    centered=False,\n",
    "    epochs=600,\n",
    "    lr=0.002,\n",
    "    INIT_DIAG=0,\n",
    "    L=15,\n",
    "    verbose=False,\n",
    "    k_fold=5,  # The number of sumsample splits\n",
    "    mode='missing'\n",
    ")  \n",
    "\n",
    "# Comparing with true precision matrix\n",
    "compare_theta_uGLAD = reportMetrics(\n",
    "        true_theta[0], \n",
    "        model_uGLAD.precision_\n",
    "    )\n",
    "print(f'uGLAD: {compare_theta_uGLAD}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd78e9e2",
   "metadata": {},
   "source": [
    "### Comparison with BCD-mean\n",
    "Run GraphicalLassoCV with mean imputed Xb_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5fa3670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCD: {'FDR': nan, 'TPR': 0.0, 'FPR': 0.0, 'SHD': 13, 'nnzTrue': 13, 'nnzPred': 0, 'precision': nan, 'recall': 0.0, 'Fbeta': 0.0, 'aupr': 0.28888888888888886, 'auc': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import GraphicalLassoCV\n",
    "\n",
    "model_BCD = GraphicalLassoCV().fit(Xb_mean[0])\n",
    "# Compare with theta\n",
    "compare_theta_BCD = reportMetrics(\n",
    "    true_theta[0], \n",
    "    model_BCD.precision_\n",
    ")\n",
    "print(f'BCD: {compare_theta_BCD}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23b1642",
   "metadata": {},
   "source": [
    "# 3. Multi-task learning mode\n",
    "- Generate synthetic data coming from graphs with varying sparsity\n",
    "- Recover the batch precision matrices for the batch input data X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c161e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_theta: (3, 10, 10), Samples (3, 500, 10)\n"
     ]
    }
   ],
   "source": [
    "# Creating synthetic data for multi-task learning \n",
    "from uGLAD.utils.prepare_data import get_data\n",
    "from uGLAD.utils.metrics import reportMetrics\n",
    "\n",
    "# Xb = samples batch, trueTheta = corresponding true precision matrices\n",
    "Xb, true_theta = get_data(\n",
    "    num_nodes=10, \n",
    "    sparsity=[0.1, 0.2], \n",
    "    num_samples=500, \n",
    "    batch_size=3,\n",
    "    eig_offset=1, \n",
    "    w_min=0.5,\n",
    "    w_max=1\n",
    ")\n",
    "print(f'true_theta: {true_theta.shape}, Samples {Xb.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a92782a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running uGLAD in multi-task mode\n",
      "Total runtime: 18.555298805236816 secs\n",
      "\n",
      "Metrics for graph 0: {'FDR': 0.8, 'TPR': 1.0, 'FPR': 0.6153846153846154, 'SHD': 24, 'nnzTrue': 6, 'nnzPred': 30, 'precision': 0.2, 'recall': 1.0, 'Fbeta': 0.3333333333333333, 'aupr': 1.0, 'auc': 1.0}\n",
      "\n",
      "Metrics for graph 1: {'FDR': 0.75, 'TPR': 1.0, 'FPR': 0.5526315789473685, 'SHD': 21, 'nnzTrue': 7, 'nnzPred': 28, 'precision': 0.25, 'recall': 1.0, 'Fbeta': 0.4, 'aupr': 0.9999999999999998, 'auc': 1.0}\n",
      "\n",
      "Metrics for graph 2: {'FDR': 0.7692307692307693, 'TPR': 1.0, 'FPR': 0.5128205128205128, 'SHD': 20, 'nnzTrue': 6, 'nnzPred': 26, 'precision': 0.23076923076923078, 'recall': 1.0, 'Fbeta': 0.375, 'aupr': 1.0, 'auc': 1.0}\n",
      "\n",
      "Avg results for uGLAD multi-task\n",
      "\n",
      "{'FDR': (0.7730769230769231, 0.020592792825909007),\n",
      " 'FPR': (0.5602789023841656, 0.0422193474646019),\n",
      " 'Fbeta': (0.36944444444444446, 0.02749859704614353),\n",
      " 'SHD': (21.666666666666668, 1.699673171197595),\n",
      " 'TPR': (1.0, 0.0),\n",
      " 'auc': (1.0, 0.0),\n",
      " 'aupr': (1.0, 1.2819751242557092e-16),\n",
      " 'nnzPred': (28.0, 1.632993161855452),\n",
      " 'nnzTrue': (6.333333333333333, 0.4714045207910317),\n",
      " 'precision': (0.22692307692307692, 0.020592792825908986),\n",
      " 'recall': (1.0, 0.0)}\n",
      "\n",
      "Total runs 3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running uGLAD in multi-task learning mode\n",
    "from uGLAD import main as uG\n",
    "from uGLAD.utils.metrics import summarize_compare_theta\n",
    "\n",
    "# Initialize the model\n",
    "model_uGLAD = uG.uGLAD_multitask()  \n",
    "\n",
    "K, M, D = Xb.shape\n",
    "\n",
    "# Fit to the data\n",
    "model_uGLAD.fit(\n",
    "    Xb,\n",
    "    centered=False,\n",
    "    epochs=200,\n",
    "    lr=0.01,\n",
    "    INIT_DIAG=0,\n",
    "    L=15,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Print the compare metrics\n",
    "compare_theta_MT = []\n",
    "for b in range(K):\n",
    "    rM = reportMetrics(\n",
    "            true_theta[b], \n",
    "            model_uGLAD.precision_[b]\n",
    "        )\n",
    "    print(f'Metrics for graph {b}: {rM}\\n')\n",
    "    compare_theta_MT.append(rM)\n",
    "\n",
    "# Calculate the average statistics\n",
    "avg_results_MT = summarize_compare_theta(compare_theta_MT, method_name='uGLAD multi-task')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f046dac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e0d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uGLAD",
   "language": "python",
   "name": "uglad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
